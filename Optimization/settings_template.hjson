{
    experiment: experiment_name
    dataset_folder: path/to/dataset

    mode: train
    # train OR inference
    direction: BtoA
    direction_inference: BtoA
    save_model_every_x_epochs: 500
    
    resume_training: 0
    epoch_count: 0 # epoch number to start/resume training at
    
    norm: instance
    netG: resnet_9blocks
    discriminator: PatchGANDiscriminator
    ngf: 64 # Number of filters in the last conv layer
    
    batch_size: 1
    pool_size: 50
    learning_rate: 0.0002
    learning_rate_fix: 3500 # No. of epochs with fixed lr
    learning_rate_decay: 3500 # No. of epochs with reduced lr
    train_d_every_x: 2 # train discriminator every x epoch
    lambda_identity: 0.5
    lambda_cycle_A: 10
    lambda_cycle_B: 10
    
    img_dim: 3 # 3 for 3D image data, 2 for 2D
    A_nc: 1 # Number of channels
    B_nc: 1
    crop_size: [32,256,256]
    # crop_size needs to be dividable by 2 at least 2 times. Dimensionality will be reduced if one element is one.
    preprocess: 'crop'
    
    inf_patch_size: [32,256,256]
    # inference patch size, null for complete image. Dimensionality will be reduced if one element is one.
    inf_patch_overlap: 0.5 # overlap between inference patches. Either value or list
}